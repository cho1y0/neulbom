"""
ìŒì„± ë¶„ì„ê¸°
Whisper + KcELECTRA + ê°œì„ ëœ ê°ì • ë¶„ì„ (PDF ê¸°ë°˜)
"""

import torch
import numpy as np
from transformers import WhisperProcessor, WhisperForConditionalGeneration, AutoTokenizer
from config.models import MODELS
from config.scoring import SCORING_CRITERIA, calculate_score
from emotion_model import EmotionEnsemble


def calculate_emotion_score(emotion_info):
    """
    ê°ì • ì•ˆì •ë„ ì ìˆ˜ ê³„ì‚°
    
    Args:
        emotion_info: EmotionEnsemble.predict() ê²°ê³¼
    
    Returns:
        score: 0-100 ì ìˆ˜
    """
    if not emotion_info or 'final_emotion' not in emotion_info:
        return 70.0
    
    final_emotion = emotion_info.get('final_emotion', 'ì¤‘ë¦½')
    confidence = emotion_info.get('audio_conf', 0.5)
    
    # ê°ì • ë¶„ë¥˜
    POSITIVE = ['ê¸°ì¨', 'í–‰ë³µ', 'happiness', 'happy']
    NEUTRAL = ['ì¤‘ë¦½', 'neutral']
    
    # ì ìˆ˜ ê³„ì‚°
    if any(pos in final_emotion.lower() for pos in POSITIVE):
        score = 80.0 + (confidence * 20.0)
    elif any(neu in final_emotion.lower() for neu in NEUTRAL):
        score = 70.0 + (confidence * 10.0)
    else:  # ë¶€ì • ê°ì •
        score = 60.0 - (confidence * 60.0)
    
    return max(0.0, min(100.0, score))


class SpeechAnalyzer:
    """ìŒì„± ë¶„ì„ê¸° (Whisper + KcELECTRA + ê°œì„ ëœ ê°ì •)"""
    
    def __init__(self):
        print("â³ ëª¨ë¸ ë¡œë”© ì¤‘... (2-3ë¶„ ì†Œìš”)")
        self.load_models()
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    
    def load_models(self):
        """ëª¨ë¸ ë¡œë“œ"""
        # GPU ì²´í¬
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Device set to use {self.device}")
        
        # Whisper (STT)
        whisper_model = MODELS['whisper']
        self.processor = WhisperProcessor.from_pretrained(whisper_model)
        self.model = WhisperForConditionalGeneration.from_pretrained(whisper_model).to(self.device)
        
        # KcELECTRA (ì–´íœ˜ ë¶„ì„)
        tokenizer_model = MODELS['tokenizer']
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_model)
        
        # ê°œì„ ëœ ê°ì • ë¶„ì„ ì—”ì§„ (PDF ê¸°ë°˜)
        self.emotion_engine = EmotionEnsemble()
    
    def analyze(self, audio_path):
        """
        ìŒì„± íŒŒì¼ ë¶„ì„ (main.py í˜¸í™˜ìš©)
        
        Args:
            audio_path: WAV íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        return self.analyze_audio(audio_path)
    
    def analyze_audio(self, audio_path):
        """
        ìŒì„± íŒŒì¼ ë¶„ì„
        
        Args:
            audio_path: WAV íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("="*60)
        print(f"ğŸ¤ ë¶„ì„ ì‹œì‘: {audio_path}")
        print("="*60)
        
        # 1. Whisper ë¶„ì„
        print("\n[1/3] ğŸ“ Whisper ë¶„ì„ ì¤‘...")
        whisper_results = self._whisper_analysis(audio_path)
        
        # 2. ì–´íœ˜ ë¶„ì„
        print("\n[2/3] ğŸ“š ì–´íœ˜ë ¥ ë¶„ì„ ì¤‘...")
        vocab_results = self._vocabulary_analysis(whisper_results['text'])
        
        # 3. ê°œì„ ëœ ê°ì • ë¶„ì„ (PDF ê¸°ë°˜)
        print("\n[3/3] â¤ï¸ ê°œì„ ëœ ê°ì • ë¶„ì„ ì¤‘...")
        emotion_results = self.emotion_engine.predict(audio_path, whisper_results['text'])
        print(f"      ğŸ‘‰ ìµœì¢… ê°ì •: {emotion_results['final_emotion']}")
        print(f"      ğŸ‘‰ í…ìŠ¤íŠ¸: {emotion_results['text_emotion']} ({emotion_results['text_conf']:.2f})")
        print(f"      ğŸ‘‰ ìŒì„±: {emotion_results['audio_emotion']} ({emotion_results['audio_conf']:.2f})")
        
        # Z-peak ì •ë³´ ì¶œë ¥
        if 'z_peak' in emotion_results:
            print(f"      ğŸ‘‰ Z-peak: {emotion_results['z_peak']:.2f}")
        
        # ê°€ì¤‘ì¹˜ ì ìš© ì´ìœ  ì¶œë ¥
        if emotion_results.get('boost_reason'):
            print(f"      ğŸ‘‰ ì ìš©ëœ ê°€ì¤‘ì¹˜:")
            for reason in emotion_results['boost_reason']:
                print(f"         â€¢ {reason}")
        
        # 4. ì ìˆ˜ ê³„ì‚° (ê°ì • í¬í•¨!)
        scores = self._calculate_scores(whisper_results, vocab_results, emotion_results)
        
        # 5. ê²°ê³¼ ì¶œë ¥
        self._print_scores(scores)
        
        # 6. ê²°ê³¼ ë°˜í™˜ (main.py í˜¸í™˜ êµ¬ì¡°)
        return {
            'features': {
                'whisper': whisper_results,
                'vocabulary': vocab_results, 
                'emotion': emotion_results
            },
            'scores': scores
        }
    
    def _whisper_analysis(self, audio_path):
        """Whisper STT ë¶„ì„"""
        import librosa
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio, sr = librosa.load(audio_path, sr=16000)
        duration = len(audio) / sr
        
        # Whisper ì²˜ë¦¬
        input_features = self.processor(
            audio, 
            sampling_rate=16000, 
            return_tensors="pt"
        ).input_features.to(self.device)
        
        # ìƒì„± (í•œêµ­ì–´ ëª…ì‹œ + ê²½ê³  ì œê±°)
        predicted_ids = self.model.generate(
            input_features,
            language="ko",
            task="transcribe"
        )
        transcription = self.processor.batch_decode(
            predicted_ids, 
            skip_special_tokens=True
        )[0]
        
        # ë‹¨ì–´ ë¶„ì„
        words = transcription.split()
        word_count = len(words)
        
        # WPM ê³„ì‚°
        wpm = (word_count / duration) * 60 if duration > 0 else 0
        
        # ë°˜ì‘ì‹œê°„ (ì²« ë‹¨ì–´ê¹Œì§€ ì‹œê°„ - ê°„ë‹¨ ì¶”ì •)
        response_time = 0.0
        
        # ì¹¨ë¬µ ë¶„ì„ (ê°„ë‹¨ ì¶”ì •)
        avg_silence = max(0, duration - (word_count * 0.5))
        
        # VPR (Vocalization-to-Pause Ratio) ê³„ì‚° - ì¶”ê°€!
        # Reference: Mundt et al. (2007)
        vpr = duration / (avg_silence + 0.01) if avg_silence > 0 else duration * 100
        
        print(f"      âœ“ í…ìŠ¤íŠ¸: {transcription}")
        print(f"      âœ“ ë‹¨ì–´ ìˆ˜: {word_count}ê°œ")
        print(f"      âœ“ WPM: {wpm:.1f}")
        print(f"      âœ“ ë°œí™”ì‹œê°„: {duration:.2f}ì´ˆ")
        print(f"      âœ“ ë°˜ì‘ì‹œê°„: {response_time:.2f}ì´ˆ")
        print(f"      âœ“ í‰ê· ì¹¨ë¬µ: {avg_silence:.2f}ì´ˆ")
        print(f"      âœ“ VPR (í™œë ¥ë„): {vpr:.2f}")  # ì¶”ê°€!
        
        return {
            'text': transcription,
            'word_count': word_count,
            'wpm': wpm,
            'duration': duration,
            'response_time': response_time,
            'avg_silence': avg_silence,
            'vpr': vpr  # VPR ì¶”ê°€!
        }
    
    def _vocabulary_analysis(self, text):
        """ì–´íœ˜ ë‹¤ì–‘ì„± ë¶„ì„"""
        if not text:
            return {
                'total_tokens': 0,
                'unique_tokens': 0,
                'ttr': 0.0
            }
        
        # í† í°í™”
        tokens = self.tokenizer.tokenize(text)
        total_tokens = len(tokens)
        unique_tokens = len(set(tokens))
        
        # TTR ê³„ì‚°
        ttr = unique_tokens / total_tokens if total_tokens > 0 else 0.0
        
        print(f"      âœ“ ì´ í† í°: {total_tokens}ê°œ")
        print(f"      âœ“ ê³ ìœ  í† í°: {unique_tokens}ê°œ")
        print(f"      âœ“ TTR: {ttr:.3f}")
        
        return {
            'total_tokens': total_tokens,
            'unique_tokens': unique_tokens,
            'ttr': ttr
        }
    
    def _calculate_scores(self, whisper_results, vocab_results, emotion_results):
        """ì ìˆ˜ ê³„ì‚° (ê°ì • + VPR í¬í•¨!)"""
        criteria = SCORING_CRITERIA
        
        scores = {
            'speed': calculate_score(
                whisper_results['wpm'],
                criteria['speed']['optimal_min'],
                criteria['speed']['optimal_max']
            ),
            'duration': calculate_score(
                whisper_results['duration'],
                criteria['duration']['optimal_min'],
                criteria['duration']['optimal_max']
            ),
            'response': calculate_score(
                whisper_results['response_time'],
                criteria['response']['optimal_min'],
                criteria['response']['optimal_max']
            ),
            'word_count': calculate_score(
                whisper_results['word_count'],
                criteria['word_count']['optimal_min'],
                criteria['word_count']['optimal_max']
            ),
            'vocabulary': calculate_score(
                vocab_results['ttr'],
                criteria['vocabulary']['optimal_min'],
                criteria['vocabulary']['optimal_max']
            ),
            'silence': calculate_score(
                whisper_results['avg_silence'],
                criteria['silence']['optimal_min'],
                criteria['silence']['optimal_max']
            ),
            # ê°ì • ì ìˆ˜ (ê¸°ì¡´)
            'emotion': calculate_emotion_score(emotion_results),
            # VPR ì ìˆ˜ (ì¶”ê°€!)
            'vitality': calculate_score(
                whisper_results['vpr'],
                criteria['vitality']['optimal_min'],
                criteria['vitality']['optimal_max']
            )
        }
        
        # í‰ê·  ì ìˆ˜
        scores['average'] = sum(scores.values()) / len(scores)
        
        return scores
    
    def _print_scores(self, scores):
        """ì ìˆ˜ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ìµœì¢… ì ìˆ˜")
        print("="*60)
        print(f"ë§ì˜ ì†ë„:    {scores['speed']:.1f}ì ")
        print(f"ë°œí™” ê¸¸ì´:    {scores['duration']:.1f}ì ")
        print(f"ë°˜ì‘ ì†ë„:    {scores['response']:.1f}ì ")
        print(f"ë‹¨ì–´ ê°œìˆ˜:    {scores['word_count']:.1f}ì ")
        print(f"ì–´íœ˜ ë‹¤ì–‘ì„±:  {scores['vocabulary']:.1f}ì ")
        print(f"ì¹¨ë¬µ íŒ¨í„´:    {scores['silence']:.1f}ì ")
        print(f"ê°ì • ì•ˆì •ë„:  {scores['emotion']:.1f}ì   â† PDF ê¸°ë°˜ ê°œì„ !")
        print(f"í™œë ¥ë„(VPR):  {scores['vitality']:.1f}ì   â† ë…¼ë¬¸ ê¸°ë°˜!")  # ì¶”ê°€!
        print()
        print(f"ğŸ¯ í‰ê·  ì ìˆ˜: {scores['average']:.1f}ì ")
        print("="*60)


# ========== í…ŒìŠ¤íŠ¸ ==========
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python analyzer.py <audio_file.wav>")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    
    analyzer = SpeechAnalyzer()
    results = analyzer.analyze_audio(audio_file)
    
    print("\në¶„ì„ ì™„ë£Œ!")