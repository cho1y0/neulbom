"""
ìŒì„± ë…¹ìŒ ëª¨ë“ˆ (ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€ ë²„ì „)
- ë°°ê²½ ì†ŒìŒ ìë™ ì¸¡ì •
- ìƒëŒ€ì  ì¹¨ë¬µ ê¸°ì¤€ (í™˜ê²½ ì ì‘í˜•)
- ë™ì  ì„ê³„ê°’ ì¡°ì •
"""

import pyaudio
import wave
import numpy as np
import time
from datetime import datetime


class AudioRecorder:
    """ì‹¤ì‹œê°„ ìŒì„± ë…¹ìŒê¸° (ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€)"""
    
    def __init__(self, 
                 sample_rate=16000,
                 channels=1,
                 chunk_size=1024,
                 silence_threshold=None,  # None = ìë™ ì¸¡ì •!
                 silence_duration=3.0,
                 auto_calibrate=True,     # ìë™ ë³´ì •
                 calibration_time=1.5):   # ë³´ì • ì‹œê°„ (ì´ˆ)
        """
        Args:
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (16000)
            channels: ì±„ë„ ìˆ˜ (1=ëª¨ë…¸)
            chunk_size: ë²„í¼ í¬ê¸°
            silence_threshold: ì¹¨ë¬µ íŒë‹¨ ê¸°ì¤€
                - None: ìë™ ì¸¡ì • (ë°°ê²½ ì†ŒìŒì˜ 2ë°°) â† ì¶”ì²œ!
                - ìˆ«ì: ì ˆëŒ€ê°’ ì‚¬ìš© (ì˜ˆ: 200)
            silence_duration: ì¹¨ë¬µ ì§€ì† ì‹œê°„ (ì´ˆ)
            auto_calibrate: ë°°ê²½ ì†ŒìŒ ìë™ ë³´ì • ì—¬ë¶€
            calibration_time: ë°°ê²½ ì†ŒìŒ ì¸¡ì • ì‹œê°„ (ì´ˆ)
        """
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.format = pyaudio.paInt16
        
        # VAD ì„¤ì •
        self.base_silence_threshold = silence_threshold
        self.silence_duration = silence_duration
        self.auto_calibrate = auto_calibrate
        self.calibration_time = calibration_time
        
        # ë™ì  ì„ê³„ê°’
        self.current_threshold = silence_threshold
        self.background_rms = None
        self.max_rms = 0
        
        # PyAudio ì´ˆê¸°í™”
        self.audio = pyaudio.PyAudio()
    
    def _calibrate_background(self, stream):
        """
        ë°°ê²½ ì†ŒìŒ ìë™ ë³´ì •
        
        Returns:
            background_rms: ë°°ê²½ ì†ŒìŒ í‰ê·  RMS
        """
        print(f"\nğŸ”Š ë°°ê²½ ì†ŒìŒ ì¸¡ì • ì¤‘... ({self.calibration_time}ì´ˆ)")
        print("   ì¡°ìš©íˆ ìˆì–´ì£¼ì„¸ìš”...")
        
        background_samples = []
        chunks_to_read = int(self.sample_rate / self.chunk_size * self.calibration_time)
        
        for i in range(chunks_to_read):
            try:
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                rms = self._calculate_rms(data)
                background_samples.append(rms)
                
                # ì§„í–‰ í‘œì‹œ
                if i % 10 == 0:
                    print(".", end="", flush=True)
            except Exception as e:
                print(f"\nâš ï¸  ì¸¡ì • ì˜¤ë¥˜: {e}")
                continue
        
        if background_samples:
            avg_background = np.mean(background_samples)
            max_background = np.max(background_samples)
            
            print(f"\nâœ… ë°°ê²½ ì†ŒìŒ ì¸¡ì • ì™„ë£Œ!")
            print(f"   í‰ê· : {avg_background:.1f} RMS")
            print(f"   ìµœëŒ€: {max_background:.1f} RMS")
            
            return avg_background
        else:
            print("\nâš ï¸  ë°°ê²½ ì†ŒìŒ ì¸¡ì • ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            return 100.0
    
    def record_until_silence(self, output_filename=None, max_duration=60):
        """
        ì¹¨ë¬µì´ ê°ì§€ë  ë•Œê¹Œì§€ ë…¹ìŒ (ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€)
        
        Args:
            output_filename: ì €ì¥í•  íŒŒì¼ ì´ë¦„ (Noneì´ë©´ ìë™ ìƒì„±)
            max_duration: ìµœëŒ€ ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        
        Returns:
            filename: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if output_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"recordings/audio_{timestamp}.wav"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        import os
        os.makedirs(os.path.dirname(output_filename) if os.path.dirname(output_filename) else ".", exist_ok=True)
        
        # ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        # 1ë‹¨ê³„: ë°°ê²½ ì†ŒìŒ ìë™ ë³´ì • (ì²˜ìŒ í•œ ë²ˆë§Œ!)
        if self.auto_calibrate and self.base_silence_threshold is None:
            # ì´ë¯¸ ì¸¡ì •í–ˆìœ¼ë©´ ì¬ì‚¬ìš©!
            if self.background_rms is None:
                self.background_rms = self._calibrate_background(stream)
                print(f"   âœ… ë°°ê²½ ì†ŒìŒ: {self.background_rms:.1f} RMS (ì¸¡ì • ì™„ë£Œ)")
            else:
                print(f"   â™»ï¸  ë°°ê²½ ì†ŒìŒ: {self.background_rms:.1f} RMS (ê¸°ì¡´ ê°’ ì‚¬ìš©)")
            
            # ì´ˆê¸° ì„ê³„ê°’: ë°°ê²½ì˜ 2ë°°
            self.current_threshold = self.background_rms * 2.0
            print(f"   ì´ˆê¸° ì¹¨ë¬µ ê¸°ì¤€: {self.current_threshold:.1f} RMS (ë°°ê²½ì˜ 2ë°°)")
        else:
            # ì ˆëŒ€ê°’ ì‚¬ìš©
            self.current_threshold = self.base_silence_threshold or 200
            print(f"   ì¹¨ë¬µ ê¸°ì¤€: {self.current_threshold:.1f} RMS (ì ˆëŒ€ê°’)")
        
        # 2ë‹¨ê³„: ì‹¤ì œ ë…¹ìŒ
        print(f"\nğŸ¤ ë…¹ìŒ ì¤€ë¹„... (ìµœëŒ€ {max_duration}ì´ˆ)")
        print(f"   ì¹¨ë¬µì´ {self.silence_duration}ì´ˆ ì§€ì†ë˜ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print(f"   ë§ì”€í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤.\n")
        
        frames = []
        silent_chunks = 0
        chunks_per_second = self.sample_rate / self.chunk_size
        silence_chunks_threshold = int(self.silence_duration * chunks_per_second)
        
        start_time = time.time()
        recording_started = False
        self.max_rms = 0
        
        # ìƒíƒœ í‘œì‹œìš© ì¹´ìš´í„°
        chunk_counter = 0
        last_status_time = start_time
        
        try:
            while True:
                # ë°ì´í„° ì½ê¸°
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                frames.append(data)
                
                # RMS ê³„ì‚°
                rms = self._calculate_rms(data)
                
                # ìµœëŒ€ RMS ì¶”ì  (ë™ì  ì„ê³„ê°’ìš©)
                if rms > self.max_rms:
                    self.max_rms = rms
                    
                    # ë™ì  ì„ê³„ê°’ ì—…ë°ì´íŠ¸ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹!)
                    if self.auto_calibrate and self.background_rms:
                        # ë°°ê²½ì˜ 2ë°° vs ìµœëŒ€ê°’ì˜ 20% ì¤‘ ë” ë†’ì€ ê°’
                        self.current_threshold = max(
                            self.background_rms * 2.0,  # ë°°ê²½ ê¸°ë°˜
                            self.max_rms * 0.2          # ë°œí™” ê¸°ë°˜
                        )
                
                # ì¹¨ë¬µ íŒì •
                is_silent = rms < self.current_threshold
                
                # ì‹œê°ì  í”¼ë“œë°± (ëª…í™•í•œ ë…¹ìŒ ìƒíƒœ í‘œì‹œ!)
                if recording_started:
                    chunk_counter += 1
                    current_time = time.time()
                    elapsed = current_time - start_time
                    
                    # 1ì´ˆë§ˆë‹¤ ìƒíƒœ í‘œì‹œ
                    if current_time - last_status_time >= 1.0:
                        silent_seconds = int(silent_chunks / chunks_per_second)
                        print(f"\rğŸ”´ [ë…¹ìŒ ì¤‘] {elapsed:05.1f}ì´ˆ | ì¹¨ë¬µ: {silent_seconds}/{int(self.silence_duration)}ì´ˆ", end="", flush=True)
                        last_status_time = current_time
                    
                    if is_silent:
                        silent_chunks += 1
                    else:
                        silent_chunks = 0
                else:
                    # ë…¹ìŒ ì‹œì‘ íŠ¸ë¦¬ê±°
                    if not is_silent:
                        recording_started = True
                        print("ğŸ”´ğŸ”´ğŸ”´ ë…¹ìŒ ì‹œì‘! ğŸ”´ğŸ”´ğŸ”´")
                        print("="*50)
                        last_status_time = time.time()
                
                # ì¢…ë£Œ ì¡°ê±´ ì²´í¬
                if recording_started:
                    # ì¹¨ë¬µ ì§€ì† í™•ì¸
                    if silent_chunks >= silence_chunks_threshold:
                        print(f"\n\nâœ… ì¹¨ë¬µ ê°ì§€ ({self.silence_duration}ì´ˆ) - ì¢…ë£Œ")
                        break
                
                # ìµœëŒ€ ì‹œê°„ í™•ì¸
                if time.time() - start_time > max_duration:
                    print(f"\n\nâ° ìµœëŒ€ ë…¹ìŒ ì‹œê°„({max_duration}ì´ˆ) ë„ë‹¬ - ì¢…ë£Œ")
                    break
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ë…¹ìŒì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        
        finally:
            stream.stop_stream()
            stream.close()
        
        # WAV íŒŒì¼ ì €ì¥
        wf = wave.open(output_filename, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(self.audio.get_sample_size(self.format))
        wf.setframerate(self.sample_rate)
        wf.writeframes(b''.join(frames))
        wf.close()
        
        # í†µê³„ ì¶œë ¥
        duration = len(frames) * self.chunk_size / self.sample_rate
        print(f"\nğŸ“Š ë…¹ìŒ í†µê³„:")
        print(f"   ì‹œê°„: {duration:.2f}ì´ˆ")
        print(f"   íŒŒì¼: {output_filename}")
        if self.background_rms:
            print(f"   ë°°ê²½ ì†ŒìŒ: {self.background_rms:.1f} RMS")
        print(f"   ìµœëŒ€ ìŒëŸ‰: {self.max_rms:.1f} RMS")
        print(f"   ìµœì¢… ì¹¨ë¬µ ê¸°ì¤€: {self.current_threshold:.1f} RMS")
        
        return output_filename
    
    def _calculate_rms(self, audio_data):
        """
        RMS (Root Mean Square) ê³„ì‚°
        
        Args:
            audio_data: ë°”ì´íŠ¸ í˜•íƒœì˜ ì˜¤ë””ì˜¤ ë°ì´í„°
        
        Returns:
            rms: RMS ê°’
        """
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            
            # ë¹ˆ ë°°ì—´ ì²´í¬
            if len(audio_array) == 0:
                return 0.0
            
            # RMS ê³„ì‚°
            mean_square = np.mean(audio_array.astype(np.float64)**2)
            
            # NaN/inf ì²´í¬
            if np.isnan(mean_square) or np.isinf(mean_square) or mean_square < 0:
                return 0.0
            
            rms = np.sqrt(mean_square)
            
            # ìµœì¢… NaN ì²´í¬
            if np.isnan(rms) or np.isinf(rms):
                return 0.0
            
            return float(rms)
        
        except Exception:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „í•œ ê°’ ë°˜í™˜
            return 0.0
    
    def test_microphone(self, duration=5):
        """
        ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ (RMS ì‹¤ì‹œê°„ í‘œì‹œ)
        
        Args:
            duration: í…ŒìŠ¤íŠ¸ ì‹œê°„ (ì´ˆ)
        """
        print(f"\nğŸ¤ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ({duration}ì´ˆ)")
        print("ë§ì„ í•´ë³´ì„¸ìš”. RMS ê°’ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\n")
        
        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )
        
        rms_values = []
        chunks_to_read = int(self.sample_rate / self.chunk_size * duration)
        
        try:
            for i in range(chunks_to_read):
                data = stream.read(self.chunk_size, exception_on_overflow=False)
                rms = self._calculate_rms(data)
                rms_values.append(rms)
                
                # ì‹œê°í™”
                bar_length = min(int(rms / 50), 40)
                bar = "â–ˆ" * bar_length
                print(f"\rRMS: {rms:6.1f}  {bar}     ", end="", flush=True)
                
                time.sleep(0.05)
        
        except KeyboardInterrupt:
            print("\n\ní…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        
        finally:
            stream.stop_stream()
            stream.close()
        
        # í†µê³„
        if rms_values:
            avg_rms = np.mean(rms_values)
            max_rms = np.max(rms_values)
            min_rms = np.min(rms_values)
            
            print(f"\n\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"   í‰ê·  RMS: {avg_rms:.1f}")
            print(f"   ìµœëŒ€ RMS: {max_rms:.1f}")
            print(f"   ìµœì†Œ RMS: {min_rms:.1f}")
            print(f"\nğŸ’¡ ì¶”ì²œ ì„¤ì •:")
            print(f"   ì ˆëŒ€ê°’ ë°©ì‹: silence_threshold={avg_rms * 1.5:.0f}")
            print(f"   ìƒëŒ€ê°’ ë°©ì‹: auto_calibrate=True (ìë™)")
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.audio.terminate()


# ========== í…ŒìŠ¤íŠ¸ ==========
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¤ ìŒì„± ë…¹ìŒ í…ŒìŠ¤íŠ¸ (ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€)")
    print("="*60)
    
    # ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€ (ìë™ ë³´ì •)
    print("\n[ëª¨ë“œ] ìƒëŒ€ì  ì¹¨ë¬µ ê°ì§€ (ìë™ ë³´ì •)")
    recorder = AudioRecorder(
        silence_threshold=None,  # ìë™!
        silence_duration=3.0,
        auto_calibrate=True
    )
    
    print("\n[1ë‹¨ê³„] ë§ˆì´í¬ í…ŒìŠ¤íŠ¸")
    recorder.test_microphone(duration=3)
    
    print("\n\n[2ë‹¨ê³„] ì‹¤ì œ ë…¹ìŒ")
    print("ë§ì„ í•˜ì„¸ìš”. ë°°ê²½ ì†ŒìŒì„ ìë™ìœ¼ë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.")
    input("ì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    
    filename = recorder.record_until_silence(max_duration=60)
    
    print(f"\në…¹ìŒ ì™„ë£Œ! íŒŒì¼: {filename}")
    
    # ì •ë¦¬
    recorder.close()